{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    read_file = open(path, 'r')\n",
    "    for line in read_file:\n",
    "        line = line.replace('\\n','')\n",
    "        items = line.split('\\t')\n",
    "        texts.append(items[0])\n",
    "        labels.append(items[1])\n",
    "    read_file.close()\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'POS_Sanskrit.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = get_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [words]\n",
    "labels = set(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv = Word2Vec(words, size=300, window=1, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = np.shape(words)\n",
    "X = []\n",
    "for i in range(n):\n",
    "    X.append(model_wv.wv[words[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29997, 300) (29997,)\n",
      "(12856, 300) (12856,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = SVC()\n",
    "#clf = KNeighborsClassifier(3)\n",
    "#clf = DecisionTreeClassifier(max_depth=5)\n",
    "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "#clf = MLPClassifier()\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.37\n",
      "Precision = 0.46\n",
      "Recall = 0.37\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {0:.2f}\".format(accuracy))\n",
    "print(\"Precision = {0:.2f}\".format(precision))\n",
    "print(\"Recall = {0:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ओं नमः श्रीशारदागणपतिगुरुभ्यः श्री शारदा गणपति गुरुभ्यः\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(tokens)):\n",
    "    test_data.append(model_wv.wv[tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'NOUN', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'NOUN'], dtype='<U23')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = FastText()\n",
    "model_ft.skipgram(input='POS_Sanskrit.txt', output='model_ft', epoch=10, lr=0.1, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(words[0])):\n",
    "    X.append(model_ft[words[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29997, 300) (29997,)\n",
      "(12856, 300) (12856,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = SVC()\n",
    "clf = KNeighborsClassifier(3)\n",
    "#clf = DecisionTreeClassifier(max_depth=5)\n",
    "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "#clf = MLPClassifier()\n",
    "#clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.69\n",
      "Precision = 0.68\n",
      "Recall = 0.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = {0:.2f}\".format(accuracy))\n",
    "print(\"Precision = {0:.2f}\".format(precision))\n",
    "print(\"Recall = {0:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ओं नमः श्रीशारदागणपतिगुरुभ्यः श्री शारदा गणपति गुरुभ्य\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(tokens)):\n",
    "    test_data.append(model_ft[tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'NOUN', '_', 'ADJ', 'X', 'VERB', 'NOUN'], dtype='<U23')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'POS_Sanskrit.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    read_file = open(path, 'r')\n",
    "    for line in read_file:\n",
    "        line = line.replace('\\n','')\n",
    "        if line == 'newline':\n",
    "            pass\n",
    "        else:\n",
    "            items = line.split('\\t')\n",
    "            texts.append(items[0])\n",
    "            labels.append(items[1])\n",
    "    read_file.close()\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, tags = get_data(path)\n",
    "words = [words]\n",
    "wvmodel = Word2Vec(words, size=300, window=1, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(words[0])):\n",
    "    X.append(wvmodel.wv[words[0][i]])\n",
    "\n",
    "\n",
    "m, n = np.shape(X)\n",
    "X = np.reshape(X, (m,n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(tags)\n",
    "y = label_encoder.transform(tags)\n",
    "y = to_categorical(y, len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                858       \n",
      "=================================================================\n",
      "Total params: 5,210\n",
      "Trainable params: 5,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='tanh', input_shape = X_train.shape[1:]))\n",
    "model.add(Dense(26, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29997 samples, validate on 12856 samples\n",
      "Epoch 1/10\n",
      "29997/29997 [==============================] - 92s 3ms/step - loss: 2.1615 - acc: 0.3001 - val_loss: 2.0805 - val_acc: 0.2986\n",
      "Epoch 2/10\n",
      "29997/29997 [==============================] - 94s 3ms/step - loss: 2.0848 - acc: 0.3007 - val_loss: 2.0803 - val_acc: 0.2986\n",
      "Epoch 3/10\n",
      "29997/29997 [==============================] - 97s 3ms/step - loss: 2.0849 - acc: 0.3007 - val_loss: 2.0780 - val_acc: 0.2986\n",
      "Epoch 4/10\n",
      "29997/29997 [==============================] - 97s 3ms/step - loss: 2.0843 - acc: 0.3007 - val_loss: 2.0816 - val_acc: 0.2986\n",
      "Epoch 5/10\n",
      "29997/29997 [==============================] - 94s 3ms/step - loss: 2.0845 - acc: 0.3007 - val_loss: 2.0821 - val_acc: 0.2986\n",
      "Epoch 6/10\n",
      "29997/29997 [==============================] - 92s 3ms/step - loss: 2.0844 - acc: 0.3007 - val_loss: 2.0809 - val_acc: 0.2986\n",
      "Epoch 7/10\n",
      "29997/29997 [==============================] - 93s 3ms/step - loss: 2.0842 - acc: 0.3007 - val_loss: 2.0800 - val_acc: 0.2986\n",
      "Epoch 8/10\n",
      "29997/29997 [==============================] - 92s 3ms/step - loss: 2.0842 - acc: 0.3007 - val_loss: 2.0808 - val_acc: 0.2986\n",
      "Epoch 9/10\n",
      "29472/29997 [============================>.] - ETA: 1s - loss: 2.0839 - acc: 0.3008"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,  batch_size = batch_size, epochs = 10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy = \",score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "pred_labels = le.inverse_transform(y_pred)\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ओं नमः श्रीशारदागणपतिगुरुभ्यः श्री शारदा गणपति गुरुभ्य\"\n",
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(tokens)):\n",
    "    test_data.append(wvmodel[tokens[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt, nt = np.shape(test_data)\n",
    "test_data = np.reshape(test_data, (mt, nt,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(test_data)\n",
    "pred_labels = le.inverse_transform(y_pred)\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
